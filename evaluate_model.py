"""
Healthcare AI System - Comprehensive Model Evaluation
Tests model performance on all critical metrics
"""

import pandas as pd
import numpy as np
import joblib
import json
from sklearn.metrics import (
    accuracy_score, precision_recall_fscore_support,
    confusion_matrix, classification_report,
    top_k_accuracy_score
)
from datetime import datetime
import os

print("=" * 80)
print("ğŸ§ª HEALTHCARE AI - KAPSAMLI MODEL DEÄERLENDÄ°RME")
print("=" * 80)

# ============================================
# 1. VERÄ° VE MODEL YÃœKLEME
# ============================================

print("\nğŸ“‚ Veri ve model yÃ¼kleniyor...")

# Model yÃ¼kleme
MODEL_DIR = r"c:\Users\muham\OneDrive\MasaÃ¼stÃ¼\AdvanceUpHackhathon\ai-service\models"
model = joblib.load(os.path.join(MODEL_DIR, "disease_classifier.joblib"))

with open(os.path.join(MODEL_DIR, "feature_columns.json"), 'r') as f:
    feature_columns = json.load(f)

with open(os.path.join(MODEL_DIR, "disease_encoding.json"), 'r') as f:
    disease_encoding = json.load(f)

label_to_disease = {item['label']: item['disease'] for item in disease_encoding}

# Test verisi yÃ¼kleme
df = pd.read_csv(r"c:\Users\muham\OneDrive\MasaÃ¼stÃ¼\AdvanceUpHackhathon\cleaned_dataset.csv")

# Train/Test split (orijinal ile aynÄ±)
from sklearn.model_selection import train_test_split

target_col = 'diseases'
exclude_cols = ['diseases', 'disease_label']
existing_feature_cols = [col for col in df.columns if col not in exclude_cols]

X = df[existing_feature_cols]
y = df['disease_label']

X_train, X_test, y_train, y_test = train_test_split(
    X, y, 
    test_size=0.2, 
    random_state=42,
    stratify=y
)

print(f"  âœ… Test set: {len(X_test):,} samples")
print(f"  âœ… Number of classes: {len(label_to_disease)}")

# ============================================
# 2. TAHMÄ°NLER
# ============================================

print("\nğŸ”® Tahminler yapÄ±lÄ±yor...")
y_pred = model.predict(X_test)
y_pred_proba = model.predict_proba(X_test)

# ============================================
# 3. TEMEL METRÄ°KLER
# ============================================

print("\n" + "=" * 80)
print("ğŸ“Š 1. TEMEL METRÄ°KLER")
print("=" * 80)

# Accuracy
accuracy = accuracy_score(y_test, y_pred)
print(f"\nâœ… Accuracy (DoÄŸruluk OranÄ±): {accuracy:.4f} ({accuracy*100:.2f}%)")

# Top-K Accuracy
top3_acc = top_k_accuracy_score(y_test, y_pred_proba, k=3)
top5_acc = top_k_accuracy_score(y_test, y_pred_proba, k=5)
top10_acc = top_k_accuracy_score(y_test, y_pred_proba, k=10)

print(f"\nğŸ¯ Top-K Accuracy (TÄ±bbi TeÅŸhis iÃ§in Kritik):")
print(f"  â€¢ Top-1 Accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)")
print(f"  â€¢ Top-3 Accuracy: {top3_acc:.4f} ({top3_acc*100:.2f}%)")
print(f"  â€¢ Top-5 Accuracy: {top5_acc:.4f} ({top5_acc*100:.2f}%)")
print(f"  â€¢ Top-10 Accuracy: {top10_acc:.4f} ({top10_acc*100:.2f}%)")

# Precision, Recall, F1
precision, recall, f1, support = precision_recall_fscore_support(
    y_test, y_pred, average=None, zero_division=0
)

print(f"\nğŸ“ˆ Ortalama SÄ±nÄ±f BazlÄ± Performans:")
print(f"  â€¢ Ortalama Precision: {np.mean(precision):.4f}")
print(f"  â€¢ Ortalama Recall: {np.mean(recall):.4f}")
print(f"  â€¢ Ortalama F1-Score: {np.mean(f1):.4f}")

# ============================================
# 4. Ã‡OK SINIFLI METRÄ°KLER
# ============================================

print("\n" + "=" * 80)
print("ğŸ“Š 2. Ã‡OK SINIFLI METRÄ°KLER")
print("=" * 80)

# Macro ve Weighted Average
precision_macro, recall_macro, f1_macro, _ = precision_recall_fscore_support(
    y_test, y_pred, average='macro', zero_division=0
)
precision_weighted, recall_weighted, f1_weighted, _ = precision_recall_fscore_support(
    y_test, y_pred, average='weighted', zero_division=0
)

print(f"\nğŸ”· Macro-Average (TÃ¼m sÄ±nÄ±flar eÅŸit aÄŸÄ±rlÄ±klÄ±):")
print(f"  â€¢ Precision: {precision_macro:.4f}")
print(f"  â€¢ Recall: {recall_macro:.4f}")
print(f"  â€¢ F1-Score: {f1_macro:.4f}")

print(f"\nğŸ”¶ Weighted-Average (Ã–rnek sayÄ±sÄ±na gÃ¶re aÄŸÄ±rlÄ±klÄ±):")
print(f"  â€¢ Precision: {precision_weighted:.4f}")
print(f"  â€¢ Recall: {recall_weighted:.4f}")
print(f"  â€¢ F1-Score: {f1_weighted:.4f}")

# En iyi ve en kÃ¶tÃ¼ performans gÃ¶steren hastalÄ±klar
df_performance = pd.DataFrame({
    'disease': [label_to_disease[i] for i in range(len(f1))],
    'precision': precision,
    'recall': recall,
    'f1_score': f1,
    'support': support
})

print(f"\nğŸ† EN Ä°YÄ° PERFORMANS GÃ–STEREN 10 HASTALIK (F1-Score):")
top_diseases = df_performance.nlargest(10, 'f1_score')
for idx, row in top_diseases.iterrows():
    print(f"  â€¢ {row['disease'][:50]:50s} | F1: {row['f1_score']:.3f} | Support: {int(row['support'])}")

print(f"\nâš ï¸ EN DÃœÅÃœK PERFORMANS GÃ–STEREN 10 HASTALIK (F1-Score):")
bottom_diseases = df_performance[df_performance['support'] > 10].nsmallest(10, 'f1_score')
for idx, row in bottom_diseases.iterrows():
    print(f"  â€¢ {row['disease'][:50]:50s} | F1: {row['f1_score']:.3f} | Support: {int(row['support'])}")

# Confusion Matrix analizi
cm = confusion_matrix(y_test, y_pred)

print(f"\nğŸ”€ Confusion Matrix Ä°statistikleri:")
print(f"  â€¢ Toplam doÄŸru tahmin: {np.trace(cm):,}")
print(f"  â€¢ Toplam yanlÄ±ÅŸ tahmin: {cm.sum() - np.trace(cm):,}")

# En Ã§ok karÄ±ÅŸan hastalÄ±k Ã§iftleri
confusion_pairs = []
for i in range(len(cm)):
    for j in range(len(cm)):
        if i != j and cm[i, j] > 5:  # En az 5 karÄ±ÅŸma
            confusion_pairs.append({
                'true_disease': label_to_disease[i],
                'predicted_disease': label_to_disease[j],
                'count': cm[i, j]
            })

confusion_pairs = sorted(confusion_pairs, key=lambda x: x['count'], reverse=True)

print(f"\nâš ï¸ EN Ã‡OK KARIÅAN 10 HASTALIK Ã‡Ä°FTÄ°:")
for pair in confusion_pairs[:10]:
    print(f"  â€¢ {pair['true_disease'][:35]:35s} â†’ {pair['predicted_disease'][:35]:35s} : {pair['count']} kez")

# ============================================
# 5. SAÄLIK ALANI Ä°Ã‡Ä°N Ã–ZEL METRÄ°KLER
# ============================================

print("\n" + "=" * 80)
print("ğŸ¥ 3. SAÄLIK ALANI Ä°Ã‡Ä°N Ã–ZEL METRÄ°KLER")
print("=" * 80)

# One-vs-Rest iÃ§in Sensitivity ve Specificity
sensitivities = []
specificities = []

for class_idx in range(len(label_to_disease)):
    # Binary classification iÃ§in hazÄ±rlÄ±k
    y_test_binary = (y_test == class_idx).astype(int)
    y_pred_binary = (y_pred == class_idx).astype(int)
    
    # True Positives, False Positives, etc.
    tp = np.sum((y_test_binary == 1) & (y_pred_binary == 1))
    tn = np.sum((y_test_binary == 0) & (y_pred_binary == 0))
    fp = np.sum((y_test_binary == 0) & (y_pred_binary == 1))
    fn = np.sum((y_test_binary == 1) & (y_pred_binary == 0))
    
    # Sensitivity (Recall) = TP / (TP + FN)
    sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0
    
    # Specificity = TN / (TN + FP)
    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0
    
    sensitivities.append(sensitivity)
    specificities.append(specificity)

avg_sensitivity = np.mean(sensitivities)
avg_specificity = np.mean(specificities)

print(f"\nğŸ¯ Sensitivity (DuyarlÄ±lÄ±k - Hasta olanlarÄ± bulma):")
print(f"  â€¢ Ortalama Sensitivity: {avg_sensitivity:.4f} ({avg_sensitivity*100:.2f}%)")
print(f"  â€¢ Min Sensitivity: {np.min(sensitivities):.4f}")
print(f"  â€¢ Max Sensitivity: {np.max(sensitivities):.4f}")

print(f"\nğŸ” Specificity (Ã–zgÃ¼llÃ¼k - SaÄŸlÄ±klÄ±larÄ± doÄŸru ayÄ±rma):")
print(f"  â€¢ Ortalama Specificity: {avg_specificity:.4f} ({avg_specificity*100:.2f}%)")
print(f"  â€¢ Min Specificity: {np.min(specificities):.4f}")
print(f"  â€¢ Max Specificity: {np.max(specificities):.4f}")

# Risk-based accuracy (Ã–rnek olarak en yaygÄ±n 20 hastalÄ±k iÃ§in)
print(f"\nâš¡ Risk-based Accuracy (YÃ¼ksek Ã¶rnekli hastalÄ±klarda baÅŸarÄ±):")

high_risk_diseases = df_performance.nlargest(20, 'support')
high_risk_accuracy = []

for idx, row in high_risk_diseases.iterrows():
    disease_name = row['disease']
    label = [k for k, v in label_to_disease.items() if v == disease_name][0]
    
    # Bu hastalÄ±k iÃ§in accuracy
    disease_mask = y_test == label
    if disease_mask.sum() > 0:
        disease_acc = accuracy_score(y_test[disease_mask], y_pred[disease_mask])
        high_risk_accuracy.append(disease_acc)
        print(f"  â€¢ {disease_name[:45]:45s} | Acc: {disease_acc:.3f} | n={int(row['support'])}")

avg_high_risk_acc = np.mean(high_risk_accuracy)
print(f"\n  ğŸ“Š Ortalama High-Risk Accuracy: {avg_high_risk_acc:.4f} ({avg_high_risk_acc*100:.2f}%)")

# ============================================
# 6. Ã–ZET RAPOR
# ============================================

print("\n" + "=" * 80)
print("ğŸ“‹ Ã–ZET RAPOR")
print("=" * 80)

summary = {
    "timestamp": datetime.now().isoformat(),
    "test_samples": len(X_test),
    "num_classes": len(label_to_disease),
    "metrics": {
        "accuracy": round(accuracy * 100, 2),
        "top3_accuracy": round(top3_acc * 100, 2),
        "top5_accuracy": round(top5_acc * 100, 2),
        "top10_accuracy": round(top10_acc * 100, 2),
        "precision_macro": round(precision_macro, 4),
        "recall_macro": round(recall_macro, 4),
        "f1_macro": round(f1_macro, 4),
        "precision_weighted": round(precision_weighted, 4),
        "recall_weighted": round(recall_weighted, 4),
        "f1_weighted": round(f1_weighted, 4),
        "avg_sensitivity": round(avg_sensitivity, 4),
        "avg_specificity": round(avg_specificity, 4),
        "high_risk_accuracy": round(avg_high_risk_acc, 4)
    },
    "interpretation": {
        "overall": "EXCELLENT" if accuracy > 0.85 else "GOOD" if accuracy > 0.75 else "NEEDS_IMPROVEMENT",
        "top3_clinical_use": "HIGHLY_SUITABLE" if top3_acc > 0.95 else "SUITABLE" if top3_acc > 0.90 else "MODERATE",
        "sensitivity": "HIGH" if avg_sensitivity > 0.80 else "MODERATE" if avg_sensitivity > 0.70 else "LOW",
        "specificity": "HIGH" if avg_specificity > 0.90 else "MODERATE" if avg_specificity > 0.80 else "LOW"
    }
}

print(f"\nâœ… GENEL BAÅARIM: {summary['interpretation']['overall']}")
print(f"   â€¢ Accuracy: {summary['metrics']['accuracy']}%")
print(f"   â€¢ Top-3 Accuracy: {summary['metrics']['top3_accuracy']}% (Klinik kullanÄ±m: {summary['interpretation']['top3_clinical_use']})")
print(f"   â€¢ Sensitivity: {summary['metrics']['avg_sensitivity']} ({summary['interpretation']['sensitivity']})")
print(f"   â€¢ Specificity: {summary['metrics']['avg_specificity']} ({summary['interpretation']['specificity']})")

# Raporu kaydet
report_path = os.path.join(MODEL_DIR, "evaluation_report.json")
with open(report_path, 'w') as f:
    json.dump(summary, f, indent=2)

print(f"\nğŸ’¾ Rapor kaydedildi: evaluation_report.json")

# ============================================
# 7. KLÄ°NÄ°K Ã–NEME GÃ–RE YORUMLAMA
# ============================================

print("\n" + "=" * 80)
print("ğŸ¥ KLÄ°NÄ°K YORUMLAMA")
print("=" * 80)

print(f"""
ğŸ¯ MODEL KARAR DESTEK SÄ°STEMÄ° OLARAK KULLANILABÄ°LÄ°R MÄ°?

âœ… GÃœÃ‡LÃœ YANLAR:
  â€¢ Top-3 accuracy %{summary['metrics']['top3_accuracy']} - Doktorlar iÃ§in 3 olasÄ± tanÄ± sunmak yeterli
  â€¢ Overall accuracy %{summary['metrics']['accuracy']} - TeÅŸhis doÄŸruluÄŸu yÃ¼ksek
  â€¢ Specificity {summary['metrics']['avg_specificity']} - Gereksiz panik yaratma riski dÃ¼ÅŸÃ¼k

âš ï¸ DÄ°KKAT EDÄ°LMESÄ° GEREKENLER:
  â€¢ Model asla nihai karar verici OLAMAZ - sadece destek sistemi
  â€¢ Nadir hastalÄ±klarda performans dÃ¼ÅŸebilir (az Ã¶rnekli sÄ±nÄ±flar)
  â€¢ Doktor geri bildirimleriyle sÃ¼rekli iyileÅŸtirme gerekli (feedback loop aktif)

ğŸ’¡ Ã–NERÄ°LER:
  â€¢ DÃ¼ÅŸÃ¼k F1 skorlu hastalÄ±klar iÃ§in daha fazla veri toplanmalÄ±
  â€¢ En Ã§ok karÄ±ÅŸan hastalÄ±k Ã§iftleri iÃ§in ayÄ±rÄ±cÄ± tanÄ± rehberleri eklenmeli
  â€¢ YÃ¼ksek riskli hastalÄ±klar iÃ§in Ã¶zel threshold ayarlarÄ± yapÄ±lmalÄ±

ğŸ“Š SONUÃ‡:
Model, {summary['interpretation']['overall']} seviyede performans gÃ¶steriyor ve
klinik karar destek sistemi olarak kullanÄ±ma uygun. Top-3 accuracy
%{summary['metrics']['top3_accuracy']} ile doktorlara anlamlÄ± Ã¶neriler sunabilir.
""")

print("\n" + "=" * 80)
print("âœ… DEÄERLENDÄ°RME TAMAMLANDI")
print("=" * 80)
