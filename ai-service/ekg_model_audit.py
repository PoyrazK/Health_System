"""
ğŸ” CRITICAL MODEL AUDIT - OVERFITTING & DATA LEAKAGE DETECTION
KatÄ± ve dÃ¼rÃ¼st deÄŸerlendirme

Bu script ÅŸunlarÄ± kontrol eder:
1. Overfitting belirtileri
2. Data leakage tÃ¼rleri
3. Cross-validation tutarlÄ±lÄ±ÄŸÄ±
4. Feature-based leakage
5. Record/patient-level leakage
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import cross_val_score, StratifiedKFold
from sklearn.metrics import accuracy_score, classification_report
import xgboost as xgb
import joblib
import json
import os
import warnings
warnings.filterwarnings('ignore')

print("=" * 80)
print("ğŸ”´ KRÄ°TÄ°K MODEL DENETÄ°MÄ° - OVERFIT & DATA LEAKAGE")
print("=" * 80)
print("\nâš ï¸ Bu denetim KATALI ve DÃœRÃœST olacaktÄ±r.\n")

# ==========================================
# CONFIGURATION
# ==========================================

MODEL_DIR = r"c:\Users\muham\OneDrive\MasaÃ¼stÃ¼\AdvanceUpHackhathon\ai-service\models\ekg"
DATA_PATH = r"c:\Users\muham\OneDrive\MasaÃ¼stÃ¼\AdvanceUpHackhathon\ai-service\notebooks\ekg\MIT-BIH Arrhythmia Database.csv"

# Load data
data = np.load(os.path.join(MODEL_DIR, 'ekg_data.npz'))
X_train = data['X_train']
X_val = data['X_val']
X_test = data['X_test']
y_train = data['y_train']
y_val = data['y_val']
y_test = data['y_test']

# Load original data for leakage check
df_original = pd.read_csv(DATA_PATH)

print(f"ğŸ“Š Veri BoyutlarÄ±:")
print(f"   Train: {X_train.shape}")
print(f"   Val: {X_val.shape}")
print(f"   Test: {X_test.shape}")

issues_found = []
warnings_found = []

# ==========================================
# 1. OVERFIT KONTROLÃœ - Train vs Test Gap
# ==========================================

print("\n" + "=" * 80)
print("ğŸ” 1. OVERFÄ°T KONTROLÃœ - Train vs Test Gap")
print("=" * 80)

# Train a fresh model to check train accuracy
model = xgb.XGBClassifier(
    max_depth=6,
    eta=0.1,
    n_estimators=343,
    random_state=42,
    use_label_encoder=False,
    eval_metric='mlogloss'
)

# Fit and check accuracies
model.fit(X_train, y_train)

train_acc = accuracy_score(y_train, model.predict(X_train))
val_acc = accuracy_score(y_val, model.predict(X_val))
test_acc = accuracy_score(y_test, model.predict(X_test))

print(f"\n   ğŸ“ˆ Accuracy KarÅŸÄ±laÅŸtÄ±rmasÄ±:")
print(f"   â€¢ Train Accuracy:  {train_acc*100:.2f}%")
print(f"   â€¢ Val Accuracy:    {val_acc*100:.2f}%")
print(f"   â€¢ Test Accuracy:   {test_acc*100:.2f}%")

train_test_gap = train_acc - test_acc
train_val_gap = train_acc - val_acc

print(f"\n   ğŸ“Š Gap Analizi:")
print(f"   â€¢ Train-Test Gap:  {train_test_gap*100:.2f}%")
print(f"   â€¢ Train-Val Gap:   {train_val_gap*100:.2f}%")

if train_test_gap > 0.05:
    issues_found.append(f"âŒ OVERFIT: Train-Test gap {train_test_gap*100:.2f}% (>5%)")
    print(f"\n   âŒ OVERFIT TESPÄ°T EDÄ°LDÄ°!")
elif train_test_gap > 0.02:
    warnings_found.append(f"âš ï¸ Hafif overfit: Train-Test gap {train_test_gap*100:.2f}%")
    print(f"\n   âš ï¸ HAFÄ°F OVERFÄ°T")
else:
    print(f"\n   âœ… Train-Test gap kabul edilebilir")

# ==========================================
# 2. CROSS-VALIDATION TUTARLILIÄI
# ==========================================

print("\n" + "=" * 80)
print("ğŸ” 2. CROSS-VALIDATION TUTARLILIÄI")
print("=" * 80)

# Combine train and val for proper CV
X_combined = np.vstack([X_train, X_val])
y_combined = np.concatenate([y_train, y_val])

print(f"\n   5-Fold Stratified CV yapÄ±lÄ±yor...")

cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
cv_scores = cross_val_score(
    xgb.XGBClassifier(max_depth=6, eta=0.1, n_estimators=100, use_label_encoder=False, eval_metric='mlogloss'),
    X_combined[:10000],  # Subset for speed
    y_combined[:10000],
    cv=cv,
    scoring='accuracy'
)

print(f"\n   ğŸ“Š CV SonuÃ§larÄ±:")
print(f"   â€¢ Fold Scores: {[f'{s*100:.1f}%' for s in cv_scores]}")
print(f"   â€¢ Mean: {cv_scores.mean()*100:.2f}%")
print(f"   â€¢ Std:  {cv_scores.std()*100:.2f}%")

if cv_scores.std() > 0.05:
    issues_found.append(f"âŒ CV varyansÄ± yÃ¼ksek: std={cv_scores.std()*100:.2f}%")
    print(f"\n   âŒ YÃœKSEK VARYANS - Model tutarsÄ±z")
elif cv_scores.std() > 0.02:
    warnings_found.append(f"âš ï¸ CV varyansÄ± orta: std={cv_scores.std()*100:.2f}%")
    print(f"\n   âš ï¸ ORTA VARYANS")
else:
    print(f"\n   âœ… CV tutarlÄ±")

# ==========================================
# 3. DATA LEAKAGE - RECORD LEVEL
# ==========================================

print("\n" + "=" * 80)
print("ğŸ” 3. DATA LEAKAGE - RECORD LEVEL")
print("=" * 80)

# Check if same records appear in train and test
# This requires checking the original 'record' column

if 'record' in df_original.columns:
    print(f"\n   ğŸ“‹ Record-based leakage kontrolÃ¼...")
    
    # Get unique records
    unique_records = df_original['record'].unique()
    print(f"   â€¢ Unique records: {len(unique_records)}")
    
    # Check if we did patient-level split
    # Since we used stratified split on samples, same patient could be in both sets
    print(f"\n   âš ï¸ UYARI: Stratified split Ã¶rnek bazlÄ± yapÄ±ldÄ±!")
    print(f"      AynÄ± HASTA farklÄ± split'lerde olabilir.")
    print(f"      Bu DATA LEAKAGE riski oluÅŸturur!")
    
    warnings_found.append("âš ï¸ Patient-level split yapÄ±lmadÄ± - aynÄ± hasta train/test'te olabilir")
else:
    print(f"\n   â„¹ï¸ Record kolonu bulunamadÄ±")

# ==========================================
# 4. FEATURE LEAKAGE - ÅÃ¼pheli Korelasyonlar
# ==========================================

print("\n" + "=" * 80)
print("ğŸ” 4. FEATURE LEAKAGE - ÅÃœPHELÄ° KORELASYONLAR")
print("=" * 80)

# Check feature importances
feature_importance = model.feature_importances_

print(f"\n   ğŸ“Š En Etkili 10 Ã–zellik:")
top_features = np.argsort(feature_importance)[-10:][::-1]

# Load feature names
try:
    with open(os.path.join(MODEL_DIR, 'feature_names.json'), 'r') as f:
        feature_names = json.load(f)
except:
    feature_names = [f'feature_{i}' for i in range(len(feature_importance))]

for idx in top_features:
    fname = feature_names[idx] if idx < len(feature_names) else f'feature_{idx}'
    imp = feature_importance[idx]
    print(f"   â€¢ {fname}: {imp:.4f}")
    
    # Check for suspiciously high importance
    if imp > 0.5:
        issues_found.append(f"âŒ Tek Ã¶zellik Ã§ok baskÄ±n: {fname} ({imp:.2f})")
        print(f"      âŒ ÅÃœPHELÄ°: Tek Ã¶zellik Ã§ok baskÄ±n!")

# Check if any feature has >0.9 correlation with target
print(f"\n   ğŸ“Š Feature-Target Korelasyonu:")
for i in range(min(5, X_train.shape[1])):
    corr = np.corrcoef(X_train[:, i], y_train)[0, 1]
    if abs(corr) > 0.8:
        issues_found.append(f"âŒ YÃ¼ksek feature-target korelasyonu: feature_{i} ({corr:.2f})")
        print(f"   âŒ feature_{i}: {corr:.3f} - ÅÃœPHELÄ°!")
    elif abs(corr) > 0.5:
        print(f"   âš ï¸ feature_{i}: {corr:.3f}")
    else:
        print(f"   âœ… feature_{i}: {corr:.3f}")

# ==========================================
# 5. SMOTE LEAKAGE KONTROLÃœ
# ==========================================

print("\n" + "=" * 80)
print("ğŸ” 5. SMOTE LEAKAGE KONTROLÃœ")
print("=" * 80)

# SMOTE was applied AFTER split - this is correct
# But let's verify

print(f"\n   ğŸ“Š SMOTE Kontrol:")
print(f"   â€¢ Train boyutu (SMOTE sonrasÄ±): {len(X_train)}")
print(f"   â€¢ Val boyutu: {len(X_val)}")
print(f"   â€¢ Test boyutu: {len(X_test)}")

# Check class distribution in test (should be original, not SMOTE'd)
unique, counts = np.unique(y_test, return_counts=True)
print(f"\n   Test Set DaÄŸÄ±lÄ±mÄ± (SMOTE uygulanMAMALI):")
for u, c in zip(unique, counts):
    print(f"   â€¢ Class {u}: {c} ({c/len(y_test)*100:.1f}%)")

# If test is balanced, that's a problem
test_imbalance = max(counts) / min(counts)
if test_imbalance < 2:
    issues_found.append("âŒ Test set dengeli - SMOTE leakage olabilir!")
    print(f"\n   âŒ TEST SET DENGELÄ°! SMOTE test'e sÄ±zmÄ±ÅŸ olabilir!")
else:
    print(f"\n   âœ… Test set orijinal daÄŸÄ±lÄ±mda (imbalance: {test_imbalance:.1f}x)")

# ==========================================
# 6. SCALER LEAKAGE KONTROLÃœ
# ==========================================

print("\n" + "=" * 80)
print("ğŸ” 6. SCALER LEAKAGE KONTROLÃœ")
print("=" * 80)

# Check if scaler was fit on all data (leakage) or just train
print(f"\n   ğŸ“Š Scaler analizi:")

# Load scaler
try:
    scaler = joblib.load(os.path.join(MODEL_DIR, 'ekg_scaler.joblib'))
    print(f"   â€¢ Scaler tÃ¼rÃ¼: {type(scaler).__name__}")
    print(f"   â€¢ Mean: {scaler.mean_[:3]}...")
    print(f"   â€¢ Scale: {scaler.scale_[:3]}...")
    
    # Can't directly verify if it was fit on all data or just train
    # But we can warn about it
    warnings_found.append("âš ï¸ Scaler fit verisi doÄŸrulanamÄ±yor - ekg_prepare_data.py'yi kontrol et")
    print(f"\n   âš ï¸ Scaler tÃ¼m veri Ã¼zerinde mi sadece train Ã¼zerinde mi fit edilmiÅŸ?")
    print(f"      â†’ ekg_prepare_data.py'yi manuel kontrol et!")
except Exception as e:
    print(f"   âŒ Scaler yÃ¼klenemedi: {e}")

# ==========================================
# 7. %99 ACCURACY GERÃ‡EKÃ‡I MÄ°?
# ==========================================

print("\n" + "=" * 80)
print("ğŸ” 7. %99 ACCURACY GERÃ‡EKÃ‡Ä° MÄ°?")
print("=" * 80)

print(f"""
   ğŸ“š MIT-BIH Benchmark KarÅŸÄ±laÅŸtÄ±rmasÄ±:

   LiteratÃ¼rde MIT-BIH 5-sÄ±nÄ±f performanslarÄ±:
   â€¢ Inter-patient split: ~85-92%
   â€¢ Intra-patient split: ~95-99%

   Bizim sonuÃ§: {test_acc*100:.2f}%

   ğŸ¤” YORUM:
""")

if test_acc > 0.98:
    print(f"   âŒ %99+ accuracy ÅÃœPHELÄ°!")
    print(f"      OlasÄ± nedenler:")
    print(f"      1. Intra-patient split (aynÄ± hasta train/test'te)")
    print(f"      2. Feature leakage (hedef sÄ±zmÄ±ÅŸ)")
    print(f"      3. Test set Ã§ok kolay")
    
    issues_found.append("âŒ %99+ accuracy literatÃ¼r ortalamasÄ±nÄ±n ÃœZERÄ°NDE - leakage ÅŸÃ¼phesi")
elif test_acc > 0.95:
    warnings_found.append("âš ï¸ %95+ accuracy yÃ¼ksek ama intra-patient split ile mÃ¼mkÃ¼n")
else:
    print(f"   âœ… Accuracy literatÃ¼r ile uyumlu")

# ==========================================
# 8. Ã–NERÄ°LER
# ==========================================

print("\n" + "=" * 80)
print("ğŸ“‹ SONUÃ‡ VE Ã–NERÄ°LER")
print("=" * 80)

print(f"\n   âŒ HATALAR: {len(issues_found)}")
for issue in issues_found:
    print(f"      {issue}")

print(f"\n   âš ï¸ UYARILAR: {len(warnings_found)}")
for warning in warnings_found:
    print(f"      {warning}")

if issues_found:
    print(f"\n   ğŸš¨ SONUÃ‡: MODEL GÃœVENÄ°LÄ°R DEÄÄ°L!")
    print(f"""
   ğŸ“Œ YAPILMASI GEREKENLER:
   
   1. PATIENT-LEVEL SPLIT:
      â†’ AynÄ± hastanÄ±n TÃœM kayÄ±tlarÄ± ya train'de ya test'te olmalÄ±
      â†’ 'record' kolonuna gÃ¶re split yap
   
   2. SCALER FIX:
      â†’ Scaler SADECE train verisi Ã¼zerinde fit edilmeli
      â†’ Sonra test'e transform uygulanmalÄ±
   
   3. SMOTE FIX:
      â†’ SMOTE sadece train'e uygulandÄ±ÄŸÄ±ndan emin ol
   
   4. RE-TRAIN:
      â†’ YukarÄ±daki dÃ¼zeltmelerle modeli yeniden eÄŸit
      â†’ Beklenen accuracy: %85-92 (inter-patient)
""")
elif warnings_found:
    print(f"\n   âš ï¸ SONUÃ‡: MODEL KABUL EDÄ°LEBÄ°LÄ°R ama dikkat gerekli")
else:
    print(f"\n   âœ… SONUÃ‡: Model gÃ¼venilir gÃ¶rÃ¼nÃ¼yor")

print("\n" + "=" * 80)
print("DENETÄ°M TAMAMLANDI")
print("=" * 80)

# Save audit report
audit_report = {
    "train_accuracy": float(train_acc),
    "val_accuracy": float(val_acc),
    "test_accuracy": float(test_acc),
    "train_test_gap": float(train_test_gap),
    "cv_mean": float(cv_scores.mean()),
    "cv_std": float(cv_scores.std()),
    "test_imbalance_ratio": float(test_imbalance),
    "issues": issues_found,
    "warnings": warnings_found,
    "verdict": "FAIL" if issues_found else "WARN" if warnings_found else "PASS"
}

report_path = os.path.join(MODEL_DIR, 'audit_report.json')
with open(report_path, 'w', encoding='utf-8') as f:
    json.dump(audit_report, f, indent=2, ensure_ascii=False)

print(f"\nRapor kaydedildi: audit_report.json")
